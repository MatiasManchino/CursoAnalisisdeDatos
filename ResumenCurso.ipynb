{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ResumenCurso.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPXSm2JHU1H0Lnn2pWHIf1g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MatiasManchino/CursoAnalisisdeDatos/blob/main/ResumenCurso.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install plotly"
      ],
      "metadata": {
        "id": "2kLpXTWWQ5zr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import plotly.express as px\n",
        "\n",
        "from IPython.display import Image\n",
        "from IPython.core.display import HTML \n",
        "\n",
        "plt.style.use('ggplot')\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "56_d49bzqT4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### datasets\n",
        "\n",
        "df1 = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/titanic.csv', sep='|')\n",
        "df2 = 0\n",
        "df3 = 0\n",
        "df4 = pd.read_csv('https://datasets-humai.s3.amazonaws.com/datasets/dolar_oficial_ambito.csv')\n",
        "df5 = 0"
      ],
      "metadata": {
        "id": "oaUBy_M5olgC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Machete para estudiar\n",
        "\n",
        "## 1.   **Clase 1**\n",
        "- a) Consultas (**columnas, filas, cantidades, informacion, descripcion, muestra de datos**)\n",
        "- b) Objetos fundamentales: **Series, DataFrame, Indices**\n",
        "- c) Filtrados: **columnas, filas, posicion, nombre, condiciones (el d), mixtas**.\n",
        "- d) Mascaras booleanas (operadores para evaluar condiciones **(==)**, operadores para sumar condiciones **(&, |)**)\n",
        "- e) Boolean con **query()**\n",
        "- f) Funciones de Agregación: **min, max, count, sum, prod, mean, median, mode, std, var**.\n",
        "- g) Otros: p/ variables numericas: **describe()**, p/ variables categoricas: **value_counts()**\n",
        "- h) Ordenar ascendente o descendente: **sort_values()**\n"
      ],
      "metadata": {
        "id": "3X-x6OyIMOwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "print(df1.columns,'\\n\\n', df1.shape)\n",
        "print('\\n')\n",
        "df1.info()\n",
        "print('\\n')\n",
        "df1.describe()\n"
      ],
      "metadata": {
        "id": "DpyyhaaKvokB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b\n",
        "#Serie\n",
        "serie = pd.Series(['a','b','c']) \n",
        "print('Tipo de objetos que tiene ', serie.dtype)\n",
        "print('Nombre ', serie.name)\n",
        "print('Index ',serie.index)\n",
        "print('Valores ',serie.values)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "#Dataset\n",
        "print('Columnas ', df1.columns) \n",
        "print('\\nIndex ', df1.index)\n",
        "print('\\nDimensiones ',df1.shape)\n",
        "\n",
        "print('\\n')\n",
        "\n",
        "#indices\n",
        "ind = pd.Index([2, 3, 5, 7, 11])\n",
        "print('\\n', ind)\n",
        "\n",
        "#ind[1] = 0 NO SE PUEDE PORQUE ES INMUTABLE\n"
      ],
      "metadata": {
        "id": "7i4gBCf_rJdH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c\n",
        "#por columnas:\n",
        "porcolumnas = df1.loc[:,['Age','Survived']]\n",
        "print(porcolumnas.head())\n",
        "\n",
        "porcolumnas1 = df1[['Age','Survived']]\n",
        "print(porcolumnas1.head())\n",
        "\n",
        "#filas\n",
        "filas = df1.loc[[1,8],:]\n",
        "print(filas.head())\n",
        "\n",
        "#posicion\n",
        "posicion = df1 ['Age'][2]\n",
        "print('\\n',posicion)"
      ],
      "metadata": {
        "id": "h36n-kFvs19V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d\n",
        "#mascaras + condiciones & | ~\n",
        "\n",
        "mascara = df1['Age'] < 3\n",
        "print('\\n', mascara) # false todo lo que no cumpla con la condicion\n",
        "\n",
        "porcondiciones = df1[(df1['Age'] < 3) & (df1['Survived'] == 1)]\n",
        "print('\\n',porcondiciones)"
      ],
      "metadata": {
        "id": "vdKW-mfo3u8o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#e \n",
        "#Query\n",
        "porquery = df1.query('Age < 3 & Survived == 1')\n",
        "porquery\n"
      ],
      "metadata": {
        "id": "Jq__uRF556In"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f\n",
        "agregacion = df1[df1.Survived == 1].pivot_table(\n",
        "    index=[\"PassengerId\"],\n",
        "    values=[\"Age\"]\n",
        ")\n",
        "#minimo\n",
        "print('Minimo',agregacion['Age'].max(),'\\n')\n",
        "#maximo\n",
        "print('Maximo',agregacion['Age'].min(),'\\n')\n",
        "#contador\n",
        "print('Contador',agregacion['Age'].count(),'\\n')\n",
        "#suma\n",
        "df1.query('Pclass == 1')['Fare'].sum()\n",
        "print('Suma',agregacion['Age'].sum(),'\\n')\n",
        "#prod\n",
        "print('Promedio',agregacion['Age'].prod(),'\\n')\n",
        "#media\n",
        "df1.query('Pclass == 2')['Age'].mean()\n",
        "print('Media',agregacion['Age'].mean(),'\\n')\n",
        "#mediana\n",
        "print('Mediana',agregacion['Age'].median(),'\\n')\n",
        "#modo\n",
        "print('Modo',agregacion['Age'].mode(),'\\n')\n",
        "#desviacion estandar\n",
        "print('Desviacion estandar',agregacion['Age'].std(),'\\n')\n",
        "#varianza\n",
        "print('Varianza',agregacion['Age'].var())"
      ],
      "metadata": {
        "id": "QcctqmTfBLYQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#g\n",
        "#p/ variables numericas\n",
        "df1.describe()\n",
        "#p/ variables categoricas\n",
        "df1['Pclass'].value_counts()\n"
      ],
      "metadata": {
        "id": "-2cJD_rfGqgQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#h\n",
        "df1.sort_values('Age', ascending=True).head(10)"
      ],
      "metadata": {
        "id": "ry2YqhbSKB9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.   **Clase 2**\n",
        "- a) Parametros y Extraccion de datos (**URL internet**, **File local**, **convertrs**)\n",
        "- b) Creador de tablas dinamicas: **Pivot Table** (index, columns, values, aggfunc)\n",
        "- c) Contar registros, crear un panel de registros (diferencias y utilización de **Pivot_table()**) estructura comun de un panel: 1 o + var numericas, 1 tempo, 1 o + no tempo\n",
        "- d) **Concat()**, concatena dos paneles en uno solo, muy importante es que los paneles sean identicos en estructura (o sea, todas las columnas llamadas igual)\n",
        "- e) **Str(), str.replace(), str.split(), map()**. Usos para transformar los datos\n",
        "- f) Merge\n"
      ],
      "metadata": {
        "id": "JQEo50DTvQLX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "\n",
        "converters = {\n",
        "    \"residencia_provincia_id\": lambda x: str(x).zfill(2),\n",
        "    \"departamento_provincia_id\": lambda x: str(x).zfill(3),\n",
        "    \"codigo_indec_provincia\": lambda x: str(x).zfill(2),\n",
        "    \"codigo_indec_departamento\": lambda x: str(x).zfill(3),\n",
        "}\n",
        "CASOS_URL_S3 = \"https://datasets-humai.s3.amazonaws.com/datasets/covid_casos.zip\"\n",
        "DETERMINACIONES_URL_S3 = \"https://datasets-humai.s3.amazonaws.com/datasets/covid_determinaciones.csv\"\n",
        "\n",
        "casos = pd.read_csv(CASOS_URL_S3, converters=converters)\n",
        "deter = pd.read_csv(DETERMINACIONES_URL_S3, converters=converters)"
      ],
      "metadata": {
        "id": "XU01MvquvpW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b\n",
        "#pivot_table()\n",
        "casos.head()\n",
        "print(casos.sexo.unique())\n",
        "porprov = casos[(casos.clasificacion_resumen == 'Sospechoso') | (casos.clasificacion_resumen == 'Confirmado') | (casos.clasificacion_resumen == 'Descartado') ].pivot_table( \n",
        "    index=['residencia_provincia_nombre'],\n",
        "    values=['id_evento_caso'],\n",
        "    aggfunc=\"count\"\n",
        ")\n",
        "porprov.sort_values(\"id_evento_caso\", ascending=False)\n",
        "casos.fallecido.value_counts()"
      ],
      "metadata": {
        "id": "ZpI6orkfn4Nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "porprov = casos[(casos.clasificacion_resumen == 'Confirmado') & (casos.fallecido == 'SI')].pivot_table( \n",
        "    index=['residencia_provincia_nombre'],\n",
        "    values=['fallecido'],\n",
        "    aggfunc=\"count\"\n",
        ")\n",
        "porprov.sort_values('fallecido', ascending=False)"
      ],
      "metadata": {
        "id": "F2N271gmgwi0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c\n",
        "#panel de registro\n",
        "panel_reg = casos[casos.clasificacion_resumen == 'Confirmado'].pivot_table(\n",
        "    index=[\n",
        "           'residencia_provincia_id',\n",
        "           'residencia_provincia_nombre',\n",
        "           \"fecha_diagnostico\"\n",
        "    ],\n",
        "    values=['id_evento_caso'],\n",
        "    aggfunc=\"count\"\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "panel = panel_reg.pivot_table(\n",
        "    index=['fecha_diagnostico'],\n",
        "    columns= ['residencia_provincia_nombre'],\n",
        "    values= ['id_evento_caso'],\n",
        "    aggfunc= [\"sum\"]\n",
        ")\n",
        "panel.plot(figsize=(35, 10))\n",
        "panel"
      ],
      "metadata": {
        "id": "1X4_jhaMn9KY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d\n",
        "#Concatenar\n",
        "panel_reg_sos = casos[casos.clasificacion_resumen == 'Sospechoso'].pivot_table( #Aca lo distinto esta en la condicion\n",
        "    index=[\n",
        "           'residencia_provincia_id',\n",
        "           'residencia_provincia_nombre',\n",
        "           \"fecha_diagnostico\"\n",
        "    ],\n",
        "    values=['id_evento_caso'],\n",
        "    aggfunc=\"count\"\n",
        ").reset_index()\n",
        "\n",
        "panel_reg_fall = casos[casos.clasificacion_resumen == 'Confirmado'].pivot_table(\n",
        "    index=[\n",
        "           'residencia_provincia_id',\n",
        "           'residencia_provincia_nombre',\n",
        "           \"fecha_fallecimiento\" #aca lo distinto esta en eeste indice\n",
        "    ],\n",
        "    values=['id_evento_caso'],\n",
        "    aggfunc=\"count\"\n",
        ").reset_index()\n",
        "#----------------------------------------------------------\n",
        "#ahora acomodar para que se esan igual estructuralemente:\n",
        "panel_reg['estado'] = 'confirmados'\n",
        "panel_reg = panel_reg.rename(columns={\n",
        "    'fecha_diagnostico': 'fecha',\n",
        "    'id_evento_caso': 'casos'\n",
        "})\n",
        "panel_reg_sos['estado'] = 'sospechoso'\n",
        "panel_reg_sos = panel_reg_sos.rename(columns={\n",
        "    'fecha_diagnostico': 'fecha',\n",
        "    'id_evento_caso': 'casos'\n",
        "})\n",
        "panel_reg_fall['estado'] = 'fallecido'\n",
        "panel_reg_fall = panel_reg_fall.rename(columns={\n",
        "    'fecha_fallecimiento': 'fecha',\n",
        "    'id_evento_caso': 'casos'\n",
        "})\n",
        "#----------------------------------------------------------\n",
        "#ha concatenar!!!! \n",
        "panel_concatenado = pd.concat([panel_reg, panel_reg_fall, panel_reg_sos])\n",
        "panel_concatenado"
      ],
      "metadata": {
        "id": "a8VkyScfn82W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#graficamos\n",
        "panel_graf = panel_concatenado.pivot_table(\n",
        "    index=['fecha'],\n",
        "    columns= ['residencia_provincia_nombre'],\n",
        "    values= ['casos'],\n",
        "    aggfunc= [\"sum\"]\n",
        ")\n",
        "panel_graf.plot(figsize=(35, 10))"
      ],
      "metadata": {
        "id": "c7qF10a6x9a0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#e\n",
        "#reemplazo\n",
        "panel_concatenado = panel_concatenado.rename( #de columnas\n",
        "    columns={'residencia_provincia_id':'id',\n",
        "             'residencia_provincia_nombre': 'prov'})\n",
        "\n",
        "panel_concatenado['prov'] = panel_concatenado.prov.str.replace( #de datos\n",
        "    'CABA', 'Capital_Federal'\n",
        ")\n",
        "panel_concatenado['prov'] = panel_concatenado.prov.map({\n",
        "    'Capital_Federal': \"Cap_Fed\",\n",
        "    'Tucumán': 'Tucu'}\n",
        ")\n",
        "panel_concatenado\n"
      ],
      "metadata": {
        "id": "uN1z0lG7n8Cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#split() Separar una columna en varias usando algun separador\n",
        "panel_concatenado['anno'],\\\n",
        " panel_concatenado['mes'],\\\n",
        "  panel_concatenado['dia'] = panel_concatenado.fecha.str.split('-').str\n",
        "\n",
        "#eliminamos la columna 'fecha'\n",
        "panel_concatenado = panel_concatenado.drop(columns= ['fecha']) \n",
        "\n",
        "panel_concatenado\n"
      ],
      "metadata": {
        "id": "31aNQpjb3gyY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f\n",
        "#merge 4 tipós distintos: 'left join', 'right join', 'inner join', 'outer join'"
      ],
      "metadata": {
        "id": "0TQY2DGqoDLf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panel_merge = pd.concat([panel_reg, panel_reg_fall, panel_reg_sos])\n",
        "panel_merge = panel_merge.rename( #de columnas\n",
        "    columns={'residencia_provincia_id':'id',\n",
        "             'residencia_provincia_nombre': 'provincia'})\n",
        "Image(url= \"https://datasets-humai.s3.amazonaws.com/datasets/joins.png\")"
      ],
      "metadata": {
        "id": "0_Ie6ot5EZa9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tengo que ver en que coniciden los dos dataset y luego generar dos paneles \n",
        "#con la misma estructura (al igual que en la concatenacion)\n",
        "\n",
        "print(deter.columns, panel_merge.columns)\n",
        "\n",
        "\n",
        "#comparten fecha y provincia\n",
        "pan_deter = deter.pivot_table(\n",
        "    index=['codigo_indec_provincia', \"fecha\"],\n",
        "    values='total',\n",
        "    aggfunc='sum'\n",
        ").reset_index()\n",
        "#pan_deter = pan_deter.rename(columns={'total':'casos'})\n",
        "pan_deter = pan_deter.rename(columns={'codigo_indec_provincia':'id'})\n",
        "\n",
        "#estrutruturo el panel de caso para el merge\n",
        "pan_caso = panel_merge.pivot_table(\n",
        "    index=['id', \"fecha\"],\n",
        "    values='casos',\n",
        "    aggfunc='sum'\n",
        ").reset_index()\n"
      ],
      "metadata": {
        "id": "sGhmU-qnExVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_casos = pan_caso.merge(\n",
        "    pan_deter,\n",
        "    left_on=[\"id\", 'fecha'],\n",
        "    right_on=[\"id\", 'fecha']\n",
        ")\n",
        "test_casos = test_casos.rename(\n",
        "    columns={\"total\": \"tests\"}\n",
        ")\n",
        "test_casos1 = pan_caso.merge(\n",
        "    pan_deter,\n",
        "    how='inner'\n",
        "    #right_on=[\"id\", 'fecha']\n",
        ")\n",
        "test_casos1"
      ],
      "metadata": {
        "id": "fC3gBwyWLKEj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig = px.histogram(test_casos1, x=\"total\")\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "gojmbaHIwzpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.   **Clase 3**\n",
        "- a) Niveles de agregación, combinación y orden, **drop_duplicates()**\n",
        "- b) Valores Nulos, **isnull()**, **any()**(evalula un elemento True)/**all()**(evalula todos elementos True) \n",
        "- c) **Dropna(inplace=bool)** metodo con el parametro se utiliza para que los metodos que se afecten a DataFrames.\n",
        "- d) Tabla de todas las funciones de agregacion (clase 1)+ any y all\n",
        "- e) El comportamiento \"lazy evaluation\", es muy importante en todos los motores de procesamiento de datos. Ejecutar las operaciones computacionalmente pesadas, sólo cuando se necesita permite hacer los procesos más eficientes. **%%timeit**\n",
        "- f) GroupBy - SeriesGroupBy\n",
        "- g) Agregaciones multiples dentro del uso de GroupBy esta el metdo **aggregate()** el cual se utiliza para agregar varios parametros en forma de diccionario con los nombres de las columnas y el tipo de agregación que se desea incluir (sum, mead, median, etc), el resultado de esto da un MultiIndex en vez de un Index ya que trabaja con varios indices (El objeto MultiIndex puede ser complicado para trabajar. Por eso conviene utilizar el método **reset_index()** para volver a un DataFrame común).\n",
        "- h) Funcion **qcut** lo que hace es agrupar los datos por mas de una columna usando una lista de valor unico como paramentro. Por ejemplo, ubicar datos que tengan una medida de localizacion (percentil, centil, decil).\n"
      ],
      "metadata": {
        "id": "iNeamy87vU0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "#Limpieza de datos\n",
        "#Elimina duplicados\n",
        "df2 = pd.DataFrame(\n",
        "    {\n",
        "        'a':[1,12,3,443,25,6,73,8,9,10],\n",
        "        'b':[1,11,21,1,1,13,1,13,1,1],\n",
        "        'c':[1,1,1,1,1,1,1,1,1,1],\n",
        "        'd':[1,1,3,4,5,6,7,8,9,0]\n",
        "    }\n",
        ")\n",
        "df2[['c','b']]#.drop_duplicates().sort_values('a')\n"
      ],
      "metadata": {
        "id": "ua26kGZbvqNh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[['c','b']].drop_duplicates()#.sort_values('a') "
      ],
      "metadata": {
        "id": "fRm12wmijj_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b\n",
        "#Valores nulos any() all()\n",
        "df2 = pd.DataFrame(\n",
        "    {\n",
        "        'a':['Uno', np.nan, 'dos', 'veinte', 'treinta', np.nan],\n",
        "        'b':['Uno', 'Doce', 'treinta', 'diez', 'treinta', 'treinta'],\n",
        "        'c':['Nueve', 'treinta', 'dos', 'treinta', 'Dos', 'treinta'],\n",
        "        'd':['tres', 1, np.nan, 'cuatro', 'treinta', 'Cinco']\n",
        "    }\n",
        ")\n",
        "df2.isnull()"
      ],
      "metadata": {
        "id": "sSgsWhskQCcl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2[df2.isnull().any(axis=1)] # df2[~(df2.notnull().all(axis=1))] ES LO MISMO"
      ],
      "metadata": {
        "id": "ddYEAfpstocV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c\n",
        "df2.dropna(inplace=True) #Elimina las filas que tienen NaN\n",
        "df2"
      ],
      "metadata": {
        "id": "aOORK0U-QGXs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Funciones de Agregación simple\n",
        "#d\n",
        "\n",
        "| Nombre             | Versión que descarta NaN | Descripción                            |\n",
        "|--------------------|--------------------------|----------------------------------------|\n",
        "| serie.sum()        | serie.sum(skipna=True)   | Suma todos los elementos               |\n",
        "| serie.prod()       | serie.prod(skipna=True)  | Multiplica                             |\n",
        "| serie.mean()       | serie.mean(skipna=True)  | Promedia                               |\n",
        "| serie.std()        | serie.std(skipna=True)   | Calcula el desvío estándar             |\n",
        "| serie.var()        | serie.var(skipna=True)   | Calcula la varianza                    |\n",
        "| serie.min()        | serie.min(skipna=True)   | Calcula el valor mínimo                |\n",
        "| serie.max()        | serie.max(skipna=True)   | Calcula el valor máximo                |\n",
        "| serie.argmin()     | serie.argmin(skipna=True)| Calcula el índice del valor mínimo     |\n",
        "| serie.argmax()     | serie.argmax(skipna=True)| Calcula el índice del valor máximo     |\n",
        "| serie.median()     | serie.median(skipna=True)| Calcula la mediana                     |\n",
        "| X                  | serie.quantile()         | Calcula los percentiles                |\n",
        "| serie.any()        | X                        | Evalúa si algún elemento es TRUE       |\n",
        "| serie.all()        | X                        | Evalúa si todos los elementos son TRUE |"
      ],
      "metadata": {
        "id": "LMpg3Ua6wMxu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#e"
      ],
      "metadata": {
        "id": "_c8M0o6nQFtM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f"
      ],
      "metadata": {
        "id": "nsvXZYqHQFNV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.groupby import groupby\n",
        "#g\n",
        "dfd = pd.DataFrame(\n",
        "    {\n",
        "        'a':['aaa', 'zz', 'cc', 'dd', 'ee', 'ff'],\n",
        "        'b':['Uno', '2', 'treinta', 'diez', 'treinta', 'treinta'],\n",
        "        'c':[423, 4231, 2, 32, 13, 5122],\n",
        "        'd':[2323, 1, 321, 23, 3213, 44],\n",
        "        'e':['Uno', '321', 'dos', 'veinte', 'treinta', 'np.na'],\n",
        "        'f':['Uno', '65', 'treinta', 'diez', 'treinta', 'treinta'],\n",
        "        'g':[23, 23, 41, 3, 1, 4],\n",
        "    }\n",
        ")\n",
        "dfd.groupby('a').aggregate({ 'b':'sum',\n",
        "                             'c':'mean',\n",
        "                             'd':'sum',\n",
        "                             'g':['mean','median','size']})"
      ],
      "metadata": {
        "id": "hpy_bI23QEzj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uh_OLZxNDf2b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#h\n",
        "dfd['Decil_Paro'] = pd.qcut(dfd['c'], 10, labels=range(1,11))\n",
        "dfd"
      ],
      "metadata": {
        "id": "51LPjzBsQD8c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.   **Clase 4**\n",
        "- a) Cadenas de caracteres: **count()** contador de ocurrencias, suele trabajar con regex, **contains()** trae las filas que contienen una cadena de caracteres determinada, **lower()** transformar todos los datos en minusculas, **upper()** transformar todos los datos en mayusculas , **title()** transformar todos los datos con la primera mayuscula y el resto en minuscula, **split()** separar dos variables que se presentan en una misma columna.\n",
        "- b) Organizar info: \n",
        "    - OLTP 4 objetivos: \n",
        "        - Operaciones atomicas: las transacciones se hacen o no se hacen no\n",
        "         existe estado inesperado\n",
        "        - Consistencia de BBDD: debe respetar una serie de restricciones\n",
        "         (ejem: tarjeta de credito debe estar anclada en una cuenta existente)\n",
        "        - Operaciones en aislamiento: significa que las opp no deben influir\n",
        "         en el estado de la BBDD incluso si llegaran a fallar.\n",
        "        - Durabilidad: que no se pierda. No habría posibilidad de revertir o \n",
        "         eliminar la transacción, solamente con una nueva operación.\n",
        "    - OLAP:  se utiliza para el analisis y reporte de negocios a partri de\n",
        "     agregacion de datos a fin de proveer informacion a los usuarios. La\n",
        "     herramienta se conoce como \"cubo de OLAP\", ya que se realiza mediante\n",
        "     una analisis multidimensional. Este es un array que permite ver\n",
        "     informacion desde distintos angulos. Requiere un proceso de carga y\n",
        "     transformacion masiva que por lo general puede durar horas e incluso dias.\n",
        "- c) Tidy date\n",
        "- d) **Melt()**, este metodo disminuye la cantidad de columnas del dataset, y crea dos nuevas, \"varialbe\" y \"value\", poniendo las columas con su valor asociado en dichas nuevas columnas respectivamente.\n",
        "- e) Series de tiempo\n",
        "    - **to_datatime()** transforma un string en un objeto de tipo Timestamp,\n",
        "     este es un objeto que estandaliza las fechas en un formato unico.\n",
        "    - **.between** filtra por rango de fechas (años, dias, meses)\n",
        "    - Para localizar los valores de una fecha determinada se pueden crear\n",
        "     columnas para cada medida de tiempo (año, mes, etc) para luego acceder\n",
        "     atraves de loc['yyyy-mm-dd']\n",
        "- f) Ventanas y medias moviles: para suavisar una serie, **.rolling().mean()** para calular la media de x. Para desplazar los datos x periodos se puede utiliazr Shitf, atregando una columna nueva con el dato anterior al pedido (**shift(perieodo=x)**). De manera similar el Diff el cual se puede ver la diferencia entre un periodo y el eanterior diff(x).\n"
      ],
      "metadata": {
        "id": "gyroBVrXvZVz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a\n",
        "#df[\"Texto\"].str.count(\"-\").head()\n",
        "df4 = pd.DataFrame(\n",
        "    {\n",
        "        'a':['aa', 'bb', 'cc', 'dd', 'ee', 'ff','gg','hh','ii','jj'],\n",
        "        'b':['Uno', '2', 'treinta','Uno', '321', 'dos', 'treinta', 'diez', 'treinta', 'treinta'],\n",
        "        'c':[423, 421, 2, 32, 13, 5122, 4231, 2, 32, 13],\n",
        "        'd':[2323, 1, 64, 23, 3213, 44, 4231, 2, 32, 13],\n",
        "        'e':['Uno', '321','Uno', '321', 'dos', 'dos', 'treinta', 'veinte', 'treinta', 'np.na'],\n",
        "        'f':['Uno', '65','Uno', '321', 'dos', 'treinta', 'diez', 'treinta', 'treinta', 'treinta'],\n",
        "        'g':[23, 23, 41, 3, 1, 4,23, 41, 3, 1],\n",
        "        'h':['aaa','Uno', '321', 'dos', 'zz', 'cc','Uno', '321', 'dos', 'dd'],\n",
        "        'i':['Uno', '2', 'treinta','Uno', '321', 'dos', 'diez', 'treinta', 'ocho' , 'treinta'],\n",
        "        'j':[423, 423, 2, 32, 13, 5122, 431, 2, 32, 3],\n",
        "        'k':[2323, 1, 321, 64, 3213, 44, 4231, 64, 32, 13],\n",
        "        'l':['Uno', '321', 'dos','Uno', '321', 'dos', 'veinte', 'treinta','ocho', 'np.na'],\n",
        "        'm':['Uno', '65', 'treinta', 'diez','65', 'treinta', 'diez', 'treinta', 'treinta', 'treinta'],\n",
        "        'n':[23, 23, 41, 3, 1, 4, 4231, 2, 32, 13]\n",
        "    }\n",
        ")\n",
        "df4[\"e\"].str.count('vei') #DONDE APARECE Y CUANTAS\n",
        "df4[\"e\"].str.count('o').value_counts()\n",
        "df4['e'][df4[\"e\"].str.count('t') ==2] #Los casos donde aparece dos veces"
      ],
      "metadata": {
        "id": "Y2tmWSMnQTxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conteinrs\n",
        "df4[df4[\"f\"].str.contains(\"ie\",case=False)] #trae tidas las filas dnde aparece una 'ie' en la columna 'f'"
      ],
      "metadata": {
        "id": "d71_httJMMiu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#mayusculas, minusculas y titulo\n",
        "may = df4[\"e\"].str.upper()\n",
        "may"
      ],
      "metadata": {
        "id": "w4MbTpVfMrov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "min = may.str.lower()\n",
        "min"
      ],
      "metadata": {
        "id": "ebGebk8xNAgH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Tit = min.str.title()\n",
        "Tit"
      ],
      "metadata": {
        "id": "7OkWDy5UNN15"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b"
      ],
      "metadata": {
        "id": "et_LMpLCQTxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c"
      ],
      "metadata": {
        "id": "NcjZxfi5QTxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d"
      ],
      "metadata": {
        "id": "PX6CTcBOQTxV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#e"
      ],
      "metadata": {
        "id": "gVt2QgCtQTxX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f"
      ],
      "metadata": {
        "id": "yZmEWmpoQTxY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5.   **Clase 5**\n",
        "- Visualizacion\n",
        "    - a) Matplotlib:\n",
        "    - b) World Bank Data API (Muchos datos empaquetados)\n",
        "    - c) Series de tiempo\n",
        "    - d) Graficos: Torta, Barras, Histograma, Diagrama de caja, Diagrama de \n",
        "     dispersión\n",
        "    - e) Plotly\n"
      ],
      "metadata": {
        "id": "NtUKLcZ4vcuM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a"
      ],
      "metadata": {
        "id": "lafxc8KfQm2j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b"
      ],
      "metadata": {
        "id": "fbeE4Pn5Qm2l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c"
      ],
      "metadata": {
        "id": "nAZPBkHxQm2o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d"
      ],
      "metadata": {
        "id": "2NlUqx1rQm2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#e"
      ],
      "metadata": {
        "id": "AmqoAYxoQm2q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CREAR UN DATASET MANUALMENTE O DESDE SERIES, NO EXTRAIDOS DIRECTAMENTE DE INTERNET**"
      ],
      "metadata": {
        "id": "hWNHi-AvvgAJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xKFsqKzyMBU0"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ]
}